

常用命令
===============


当前日期
--------------
```
当前日期
date

昨天
date -d '1 days ago'

格式化显示
date +%Y%m%d
date +%Y-%m-%d
date -d '1 days ago' +%Y%m%d

指定日期的前一天
date -d"yesterday 20150401" +%Y%m%d

指定日期的前几天
date -d"10 day ago 2015-04-01" +%Y-%m-%d

时间戳转化为时间
date -d "1279592730"

date -d "1279592730" +"%Y-%m-%d %H:%M:%S"
或者
date -d "1279592730" +"%F %H:%M:%S" 


```


source
---------------
source filepath 或 . filepath

功能：使当前shell读入路径为filepath的shell文件并依次执行文件中的所有语句，通常用于重新执行刚修改的初始化文件，使之立即生效，而不必注销并重新登录。例如，当我们修改了/etc/profile文件，并想让它立刻生效，而不用重新登录，就可以使用source命令，如source /etc/profile。

source命令(从 C Shell 而来)是bash shell的内置命令；点命令(.)，就是个点符号(从Bourne Shell而来)是source的另一名称。这从用法中也能看出来。

```
新建一个test.sh脚本，内容为:A=1；

修改其可执行权限：chmod +x test.sh；

运行sh test.sh后，echo $A，显示为空，因为A=1并未传回给当前shell；

运行./test.sh后，也是一样的效果；

运行source test.sh 或者 . test.sh，然后echo $A，则会显示1，说明A=1的变量在当前shell中；
```


软链接
---------------
```
命令格式：
ln -s [源文件或目录] [目标文件或目录]
```

ln -s a b 中的 a 就是源文件，b是链接文件名，其作用是当进入b目录，实际上是链接进入了a目录

如上面的示例，当我们执行命令  cd /gamestat/的时候  实际上是进入了 /home/gamestat/

值得注意的是执行命令的时候，应该是a目录已经建立，目录b没有建立。

删除软链接：
> rm -rf b  注意不能是rm -rf  b/



tar
---------------
```
#打tar包，如果要打包的是多个目录，则以空格分隔即可
tar -zcvf business.tar.gz 待压缩的目录
tar -zcvf business.tar.gz app conf webroot php


#把某压缩包解压到指定目录下，-C指定将要解压到何处。如果不指定，则在当前目录下(此时不需-C和指定目录)
tar zxvf output/xxxx.tar.gz
tar zxvf output/xxxx.tar.gz -C /aaa/bbb/ccc
```



top
---------------
#查看进程的信息
top

#查看指定进程的信息
top -p 进程号

#查看线程的信息
top -H

#查看指定线程的信息
top -H -p <pid>





ps
---------------
ps -ef  
显示的列表信息中带父进程id  
```
UID        PID  PPID  C STIME TTY          TIME CMD
503      45980     1  0 15:02 pts/1    00:00:01 doc_multi_process_master 45980
503      45993 45980  0 15:02 pts/1    00:00:04 doc_multi_process_worker 45993
503      45994 45980  0 15:02 pts/1    00:00:05 doc_multi_process_worker 45994
503      45995 45980  0 15:02 pts/1    00:00:05 doc_multi_process_worker 45995

其中各列的内容意思如下：
UID    //用户ID、但输出的是用户名 
PID    //进程的ID 
PPID    //父进程ID 
C      //进程占用CPU的百分比 
STIME  //进程启动到现在的时间 
TTY    //该进程在那个终端上运行，若与终端无关，则显示? 若为pts/0等，则表示由网络连接主机进程。 
CMD    //命令的名称和参数
```

ps -aux   
显示的列表信息不带父进程id，但是会显示该进程的cpu、mem占用百分比、启动时间(开始时间)  
```
USER       PID %CPU %MEM   VSZ  RSS TTY      STAT START   TIME COMMAND
503      45980  0.0  3.3 338220 134844 pts/1 Sl   15:02   0:01 doc_multi_process_master 45980
503      45993  0.0  1.1 338220 45016 pts/1  S    15:02   0:04 doc_multi_process_worker 45993
503      45994  0.0  1.2 345436 52312 pts/1  S    15:02   0:05 doc_multi_process_worker 45994
503      45995  0.0  1.2 345436 51164 pts/1  S    15:02   0:05 doc_multi_process_worker 45995

其中各列的内容意思如下：
USER      //用户名 
%CPU      //进程占用的CPU百分比 
%MEM      //占用内存的百分比 
VSZ      //该进程使用的虚拟內存量（KB） 
RSS      //该进程占用的固定內存量（KB）（驻留中页的数量） 
STAT      //进程的状态 
START    //该进程被触发启动时间 
TIME      //该进程实际使用CPU运行的时间

其中STAT状态位常见的状态字符有
D      //无法中断的休眠状态（通常 IO 的进程）； 
R      //正在运行，在队列中可过行的； 
S      //处于休眠状态； 
T      //停止或被追踪； 
W      //进入内存交换 （从内核2.6开始无效）； 
X      //死掉的进程 （基本很少见）； 
Z      //僵尸进程； 
<      //优先级高的进程 
N      //优先级较低的进程 
L      //有些页被锁进内存； 
s      //进程的领导者（在它之下有子进程）； 
l      //多线程，克隆线程（使用 CLONE_THREAD, 类似 NPTL pthreads）； 
+      //位于后台的进程组；
```



top -p 进程号
可以单独只查看一个进程的信息


查看更详细的内存情况：
```
cat /proc/进程号/status
结果中 VmRSS 为内存
```


pstree
---------------
#查看进程树
pstree

#查看进程树，并打印每个进程的PID
pstree -p

#查看某个进程树型结构
pstree -p <pid> 


tree
---------------
#查看某个目录的目录树
> tree 目录名

#查看目录树，同时打印出文件大小
> tree -h /tmp/txt



查看某个文件被哪些进程在读写
--------------
lsof是什么意思：list open files

查看某个文件被哪些进程在读写
> lsof 文件名

查看某个进程打开了哪些文件
> lsof –c 进程名
> lsof –p 进程号

lsof更多用法
```
lsof abc.txt 显示开启文件abc.txt的进程
lsof -i :22 知道22端口现在运行什么程序
lsof -c nsd 显示nsd进程现在打开的文件
lsof -g gid 显示归属gid的进程情况
lsof +d /usr/local/ 显示目录下被进程开启的文件
lsof +D /usr/local/ 同上，但是会搜索目录下的目录，时间较长
lsof -d 4 显示使用fd为4的进程
lsof -i [i] 用以显示符合条件的进程情况
```

Linux查看进程运行的完整路径方法
---------------
通过ps及top命令查看进程信息时，只能查到相对路径，查不到的进程的详细信息，如绝对路径等。这时，我们需要通过以下的方法来查看进程的详细信息：

Linux在启动一个进程时，系统会在/proc下创建一个以PID命名的文件夹，在该文件夹下会有我们的进程的信息，其中包括一个名为exe的文件即记录了绝对路径，通过ll或ls –l命令即可查看。
> ll /proc/PID

```
cwd符号链接的是进程运行目录；

exe符号连接就是执行程序的绝对路径；

cmdline就是程序运行时输入的命令行命令；

environ记录了进程运行时的环境变量；

fd目录下是进程打开或使用的文件的符号连接。
```



grep 
---------------
文本搜集工具, 结合正则表达式非常强大
主要参数 []
-c : 只输出匹配的行
-I : 不区分大小写
-h : 查询多文件时不显示文件名
-l : 查询多文件时, 只输出包含匹配字符的文件名
-n : 显示匹配的行号及行
-v : 显示不包含匹配文本的所有行(我经常用除去grep本身)
基本工作方式: grep 要匹配的内容 文件名, 例如:
```
grep 'test' d* 显示所有以d开头的文件中包含test的行
grep 'test' aa bb cc 显示在 aa bb cc 文件中包含test的行
grep '[a-z]\{5}\' aa 显示所有包含字符串至少有5个连续小写字母的串

grep -n 'test' d* 显示所有以d开头的文件中包含test的行，并且带上行号


查看php.ini文件(不含注释和空行)，如果想带上行号补上参数-n即可
grep -v '^;' php.ini |grep -v '^$' 
cat php.ini | grep -v '^;' |grep -v '^$' 
```



find
---------------
例：
find . -name .svn | xargs rm -rf

```
-name   filename             #查找名为filename的文件
-perm                        #按执行权限来查找
-user    username             #按文件属主来查找
-group groupname            #按组来查找
-mtime   -n +n                #按文件更改时间来查找文件，-n指n天以内，+n指n天以前
-atime    -n +n               #按文件访问时间来查GIN: 0px">

-ctime    -n +n              #按文件创建时间来查找文件，-n指n天以内，+n指n天以前

-nogroup                     #查无有效属组的文件，即文件的属组在/etc/groups中不存在
-nouser                     #查无有效属主的文件，即文件的属主在/etc/passwd中不存
-newer   f1 !f2              找文件，-n指n天以内，+n指n天以前 
-ctime    -n +n               #按文件创建时间来查找文件，-n指n天以内，+n指n天以前 
-nogroup                     #查无有效属组的文件，即文件的属组在/etc/groups中不存在
-nouser                      #查无有效属主的文件，即文件的属主在/etc/passwd中不存
-newer   f1 !f2               #查更改时间比f1新但比f2旧的文件
-type    b/d/c/p/l/f         #查是块设备、目录、字符设备、管道、符号链接、普通文件
-size      n[c]               #查长度为n块[或n字节]的文件
-depth                       #使查找在进入子目录前先行查找完本目录
-fstype                     #查更改时间比f1新但比f2旧的文件
-type    b/d/c/p/l/f         #查是块设备、目录、字符设备、管道、符号链接、普通文件
-size      n[c]               #查长度为n块[或n字节]的文件
-depth                       #使查找在进入子目录前先行查找完本目录
-fstype                      #查位于某一类型文件系统中的文件，这些文件系统类型通常可 在/etc/fstab中找到
-mount                       #查文件时不跨越文件系统mount点
-follow                      #如果遇到符号链接文件，就跟踪链接所指的文件
-cpio                %;      #查位于某一类型文件系统中的文件，这些文件系统类型通常可 在/etc/fstab中找到
-mount                       #查文件时不跨越文件系统mount点
-follow                      #如果遇到符号链接文件，就跟踪链接所指的文件
-cpio                        #对匹配的文件使用cpio命令，将他们备份到磁带设备中
-prune                       #忽略某个目录

=====================================================

find   ~   -name   "*.txt"   -print    #在$HOME中查.txt文件并显示
find   .    -name   "*.txt"   -print
find   .    -name   "[A-Z]*"   -print   #查以大写字母开头的文件
find   /etc   -name   "host*"   -print #查以host开头的文件
find   .   -name   "[a-z][a-z][0–9][0–9].txt"    -print   #查以两个小写字母和两个数字开头的txt文件
find   .   -perm   755   -print
find   .   -perm -007   -exec ls -l {} \;   #查所有用户都可读写执行的文件同-perm 777
find   . -type d   -print
find   .   !   -type   d   -print 
find   .   -type l   -print

find   .   -size   +1000000c   -print        #查长度大于1Mb的文件
find   .   -size   100c         -print       # 查长度为100c的文件
find   .   -size   +10   -print              #查长度超过期作废10块的文件（1块=512字节）

cd /
find   etc   home   apps    -depth   -print   | cpio   -ivcdC65536   -o   /dev/rmt0
find   /etc -name "passwd*"   -exec grep   "cnscn"   {}   \;   #看是否存在cnscn用户
find   . -name "yao*"   | xargs file
find   . -name "yao*"   |   xargs   echo    "" > /tmp/core.log
find   . -name "yao*"   | xargs   chmod   o-w

======================================================

find   -name april*                     在当前目录下查找以april开始的文件
find   -name   april*   fprint file        在当前目录下查找以april开始的文件，并把结果输出到file中
find   -name ap* -o -name may*   查找以ap或may开头的文件
find   /mnt   -name tom.txt   -ftype vfat   在/mnt下查找名称为tom.txt且文件系统类型为vfat的文件
find   /mnt   -name t.txt ! -ftype vfat   在/mnt下查找名称为tom.txt且文件系统类型不为vfat的文件
find   /tmp   -name wa* -type l            在/tmp下查找名为wa开头且类型为符号链接的文件
find   /home   -mtime   -2                 在/home下查最近两天内改动过的文件
find   /home   -atime -1                  查1天之内被存取过的文件
find   /home   -mmin    +60                  在/home下查60分钟前改动过的文件
find   /home   -amin   +30                  查最近30分钟前被存取过的文件
find   /home   -newer   tmp.txt             在/home下查更新时间比tmp.txt近的文件或目录
find   /home   -anewer   tmp.txt            在/home下查存取时间比tmp.txt近的文件或目录
find   /home   -used   -2                  列出文件或目录被改动过之后，在2日内被存取过的文件或目录
find   /home   -user cnscn                列出/home目录内属于用户cnscn的文件或目录
find   /home   -uid   +501                  列出/home目录内用户的识别码大于501的文件或目录
find   /home   -group   cnscn              列出/home内组为cnscn的文件或目录
find   /home   -gid 501                   列出/home内组id为501的文件或目录
find   /home   -nouser                    列出/home内不属于本地用户的文件或目录
find   /home   -nogroup                   列出/home内不属于本地组的文件或目录
find   /home   -name tmp.txt    -maxdepth   4   列出/home内的tmp.txt 查时深度最多为3层
find   /home   -name tmp.txt   -mindepth   3   从第2层开始查
find   /home   -empty                     查找大小为0的文件或空目录
find   /home   -size   +512k                查大于512k的文件
find   /home   -size   -512k               查小于512k的文件
find   /home   -links   +2                查硬连接数大于2的文件或目录
find   /home   -perm   0700                查权限为700的文件或目录
find   /tmp    -name   tmp.txt   -exec cat {} \;
find   /tmp    -name   tmp.txt   -ok   rm {} \;

find    /   -amin    -10      # 查找在系统中最后10分钟访问的文件
find    /   -atime   -2       # 查找在系统中最后48小时访问的文件
find    /   -empty            # 查找在系统中为空的文件或者文件夹
find    /   -group   cat      # 查找在系统中属于 groupcat的文件
find    /   -mmin   -5        # 查找在系统中最后5分钟里修改过的文件
find    /   -mtime   -1       # 查找在系统中最后24小时里修改过的文件
find    /   -nouser           # 查找在系统中属于作废用户的文件
find    /   -user    fred     # 查找在系统中属于FRED这个用户的文件


find / -name "*.txt" |xargs grep "www.dutycode.com"  #在某目录中查找所有含某字串的文件
```



awk
---------------
awk处理机制：  
awk会逐行处理文本，支持在处理第一行之前做一些准备工作，以及在处理完最后一行做一些总结性质的工作，在命令格式上分别体现如下：
```
BEGIN{}   :读入第一行文本之前执行，一般用来初始化操作
{}        :逐行处理，逐行读入文本执行相应的处理，是最常见的编辑指令块
END{}     :处理完最后一行文本之后执行，一般用来输出处理结果
```

所以, AWK一次处理是一行, 而一次中处理的最小单位是一个区域
另外还有3个变量, NF: 每一行处理的字段数, NR 目前处理到第几行 FS 目前的分隔符
逻辑判断 > < >= <= == !== , 赋值直接使用=

cat /etc/passwd | awk '{FS=":"} $3<10 {print $1 "\t" $3}' 首先定义分隔符为:, 然后判断, 注意看, 判断没有写在{}中, 然后执行动作, FS=":"这是一个动作, 赋值动作, 不是一个判断, 所以不写在{}中

BEGIN END , 给程序员一个初始化和收尾的工作, BEGIN之后列出的操作在{}内将在awk开始扫描输入之前执行, 而END{}内的操作, 将在扫描完输入文件后执行.

awk '/test/ {print NR}' abc 将带有test的行的行号打印出来, 注意//之间可以使用正则表达式
awk {}内, 可以使用 if else ,for(i=0;i<10;i++), i=1 while(i<NF)

$0:表示当前行
$1:表示当前行的第一列
$2:表示当前行的第二列
$NF:表示当前行的最后一列


awk有许多内置变量用来设置环境信息，这些变量可以被改变，下面给出了最常用的一些变量。

ARGC               命令行参数个数
ARGV               命令行参数排列
ENVIRON            支持队列中系统环境变量的使用
FILENAME           awk浏览的文件名
FNR                浏览文件的记录数
FS                 设置输入域分隔符，等价于命令行 -F选项
NF                 浏览记录的域的个数
NR                 已读的记录数
OFS                输出域分隔符
ORS                输出记录分隔符
RS                 控制记录分隔符


```
ll | awk '{print $1}'

#-F指定域分隔符为':'；如果不指定，默认的分隔符是空格键或tab键
cat /etc/passwd | awk -F ':' '{print $1}'
cat /etc/passwd | awk -F ':' '{print $1"\t"$7}'
```

如果只是显示/etc/passwd的账户和账户对应的shell,而账户与shell之间以逗号分割,而且在所有行添加列名name,shell,在最后一行添加"blue,/bin/nosh"。
```
cat /etc/passwd |awk -F ':' 'BEGIN {print "name,shell"} {print $1","$7} END {print "blue,/bin/nosh"}'
输出：
name,shell
root,/bin/bash
daemon,/bin/sh
bin,/bin/sh
sys,/bin/sh
....
blue,/bin/nosh
```

搜索/etc/passwd有root关键字的所有行

```
awk -F: '/root/' /etc/passwd
root:x:0:0:root:/root:/bin/bash
```
这种是pattern的使用示例，匹配了pattern(这里是root)的行才会执行action(没有指定action，默认输出每行的内容)。

搜索支持正则，例如找root开头的: awk -F: '/^root/' /etc/passwd

搜索/etc/passwd有root关键字的所有行，并显示对应行号和shell

```
awk -F: '/root/{print NR,$7}' /etc/passwd       
输出：
/bin/bash
```
这里指定了action{print NR,$7}


统计/etc/passwd:文件名，每行的行号，每行的列数，对应的完整行内容:

```
awk -F ':' '{print "filename:" FILENAME ",linenumber:" NR ",columns:" NF ",linecontent:"$0}' /etc/passwd
输出：
filename:/etc/passwd,linenumber:1,columns:7,linecontent:root:x:0:0:root:/root:/bin/bash
filename:/etc/passwd,linenumber:2,columns:7,linecontent:daemon:x:1:1:daemon:/usr/sbin:/bin/sh
filename:/etc/passwd,linenumber:3,columns:7,linecontent:bin:x:2:2:bin:/bin:/bin/sh
filename:/etc/passwd,linenumber:4,columns:7,linecontent:sys:x:3:3:sys:/dev:/bin/sh
```
使用printf替代print,可以让代码更加简洁，易读
```
awk -F ':' '{printf("filename:%10s,linenumber:%s,columns:%s,linecontent:%s\n",FILENAME,NR,NF,$0)}' /etc/passwd
```


只输出满足条件的
```
awk -F '\t' '$28==10001 {print $19,$28, $31, $34}' qiantest4-20190103 | sort | uniq -c

awk -F '\t' '$28==10001 {print $2, $19,$28, $31, $34}' qiantest4-20190103 | sort
```


除了awk的内置变量，awk还可以自定义变量。
下面统计/etc/passwd的账户人数
```
awk '{count++;print $0;} END{print "user count is ", count}' /etc/passwd
root:x:0:0:root:/root:/bin/bash
......
user count is 40
```
count是自定义变量。之前的action{}里都是只有一个print,其实print只是一个语句，而action{}可以有多个语句，以;号隔开。

这里没有初始化count，虽然默认是0，但是妥当的做法还是初始化为0:
```
awk 'BEGIN {count=0;print "[start]user count is ", count} {count=count+1;print $0;} END{print "[end]user count is ", count}' /etc/passwd
[start]user count is 0
root:x:0:0:root:/root:/bin/bash
...
[end]user count is 40
```


统计某个文件夹下的文件占用的字节数
```
ls -l |awk 'BEGIN {size=0;} {size=size+$5;} END{print "[end]size is ", size}'
[end]size is 8657198
```
如果以M为单位显示:
```
ls -l |awk 'BEGIN {size=0;} {size=size+$5;} END{print "[end]size is ", size/1024/1024,"M"}'
[end]size is 8.25889 M
```

统计某个文件夹下的文件占用的字节数,过滤4096大小的文件(一般都是文件夹):
```
ls -l |awk 'BEGIN {size=0;print "[start]size is ", size} {if($5!=4096){size=size+$5;}} END{print "[end]size is ", size/1024/1024,"M"}'
[end]size is 8.22339 M
```

显示/etc/passwd的账户
```
awk -F ':' 'BEGIN {count=0;} {name[count] = $1;count++;}; END{for (i = 0; i < NR; i++) print i, name[i]}' /etc/passwd
0 root
1 daemon
2 bin
3 sys
4 sync
5 games
......
```

更多示例：
```
1 awk -F ":" '{print $1}' passwd  #以:为分隔符，显示第一列
2 awk -F ":" '{print NR,$0}' passwd  #以:为分隔符打印第一列，并表示行号，$0表示文件一整行的内容
3 awk -F ":" 'BEGIN{print "NAME"}{print $1}'  passwd  #以NAME开始显示第一列
4 awk -F ":" 'BEGIN{print "NAME"}{print NR,$1}END{print "END"}'  passwd #以NAME开始，以END结束，显示第一列并显示行号
5 awk -F ":" 'BEGIN{print "NAME"}{print NR;print  }END{print "END"}'  passwd #显示行号并换行

6 awk -F ":" '$1=='abc'  {print $1}' passwd   #只输出第一列值为abc的记录

6 awk -F ":" '/bash$/{print $1}' passwd   #sh结尾的行的第一列,$1表示第一列

7 awk -F ":" 'BEGIN{N=0}/bash$/{N++}END{print N}'  passwd  #统计passwd中以bash结尾的行数
8 awk '/^ro/{print}' passwd      #打印以ro开头的行
9 awk '/^[^a-d]/{print}' passwd  #打印以a到d开头的行
10 awk '/^a|nologin$/{print}'  passwd  #打印以a开头或者以nologin结尾的行
11 awk -F ":" '$1~/^r/{print}'  passwd #打印以r开头的行
12 awk -F ":" '$1!~/^r/{print}'  passwd  #打印不以r开头的行


awk -F '\t' '$1=="20181126" && $4==70000 && $7=="xxx.com" && $8=="/view/id" && $9=="wenku" {print $3}' test_xxxx | sort | wc -l
```






sed
---------------
以行为单位的文本编辑工具 sed可以直接修改档案, 不过一般不推荐这么做, 可以分析 standard input

基本工作方式: sed [-nef] '[动作]' [输入文本]
-n : 安静模式, 一般sed用法中, 来自stdin的数据一般会被列出到屏幕上, 如果使用-n参数后, 只有经过sed处理的那一行被列出来.
-e : 多重编辑, 比如你同时又想删除某行, 又想改变其他行, 那么可以用 sed -e '1,5d' -e 's/abc/xxx/g' filename
-f : 首先将 sed的动作写在一个档案内, 然后通过 sed -f scriptfile 就可以直接执行 scriptfile 内的sed动作 (没有实验成功, 不推荐使用)
-i : 直接编辑, 这回就是真的改变文件中的内容了, 别的都只是改变显示. (不推荐使用)

动作:
a 新增, a 后面可以接字符串, 而这个字符串会在新的一行出现. (下一行)
c 取代, c 后面的字符串, 这些字符串可以取代 n1,n2之间的行
d 删除, 后面不接任何东西
i 插入, 后面的字符串, 会在上一行出现，(注意区分a与i)
p 打印, 将选择的资料列出, 通常和 sed -n 一起运作 sed -n '3p' 只打印第3行
s 取代, 类似vi中的取代, 1,20s/old/new/g

```
[line-address]q 退出, 匹配到某行退出, 提高效率

[line-address]r 匹配到的行读取某文件 例如: sed '1r qqq' abc , 注意, 写入的文本是写在了第1行的后边, 也就是第2行

[line-address]w file, 匹配到的行写入某文件  例如: sed -n '/m/w qqq' abc , 从abc中读取带m的行写到qqq文件中, 注意, 这个写入带有覆盖性.
```


举例:

删除某行
```
[root@localhost ruby] # sed '1d' ab       #删除第一行 
[root@localhost ruby] # sed '$d' ab       #删除最后一行
[root@localhost ruby] # sed '1,2d' ab      #删除第一行到第二行
[root@localhost ruby] # sed '2,$d' ab      #删除第二行到最后一行
注：$符号正则表达式中表示行末尾，^开头

sed '/test/d' abc   #文件中所有带 test 的行, 全部删除
```

显示某行
```
[root@localhost ruby] # sed -n '1p' ab      #显示第一行 
[root@localhost ruby] # sed -n '$p' ab      #显示最后一行
[root@localhost ruby] # sed -n '1,2p' ab    #显示第一行到第二行
[root@localhost ruby] # sed -n '2,$p' ab    #显示第二行到最后一行
```

使用模式进行查询
```
[root@localhost ruby] # sed -n '/ruby/p' ab  #查询包括关键字ruby所在所有行
[root@localhost ruby] # sed -n '/\$/p' ab    #查询包括关键字$所在所有行，使用反斜线\屏蔽特殊含义
```

增加一行或多行字符串	
```
[root@localhost ruby]# cat ab
Hello!
ruby is me,welcome to my blog.
end
[root@localhost ruby] # sed '1a drink tea' ab #第一行后增加字符串"drink tea"
Hello!
drink tea
ruby is me,welcome to my blog. 
end

[root@localhost ruby] # sed '1,3a drink tea' ab #第一行到第三行后增加字符串"drink tea"
Hello!
drink tea
ruby is me,welcome to my blog.
drink tea
end
drink tea

[root@localhost ruby] # sed '1a drink tea\nor coffee' ab  #第一行后增加多行，使用换行符\n
Hello!
drink tea
or coffee
ruby is me,welcome to my blog.
end
```

代替一行或多行

```
[root@localhost ruby] # sed '1c Hi' ab        #第一行代替为Hi
Hi
ruby is me,welcome to my blog.
end

[root@localhost ruby] # sed '1,2c Hi' ab       #第一行到第二行代替为Hi
Hi
end

sed '/test/c RRRRRRR' abc 将 RRRRRRR 替换所有带 test 的行
sed '1,5c RRRRRRR' abc
```

替换一行中的某部分
```
格式：sed 's/要替换的字符串/新的字符串/g'   （要替换的字符串可以用正则表达式）
[root@localhost ruby] # sed -n '/ruby/p' ab | sed 's/ruby/bird/g'  #替换ruby为bird
[root@localhost ruby] # sed -n '/ruby/p' ab | sed 's/ruby//g'    #删除ruby
```

插入
```
sed '/test/a RRRRRRR' abc 将 RRRRRRR 追加到所有的带 test 行的下一行 
sed '1,5c RRRRRRR' abc 

[root@localhost ruby] # sed -i '$a bye' ab     #在文件ab中最后一行直接输入"bye"
[root@localhost ruby]# cat ab
Hello!
ruby is me,welcome to my blog.
end
bye
```


wc -l
---------------
统计结果行数
wc -l


sort
---------------
```
-b   忽略每行前面开始出的空格字符。
-c   检查文件是否已经按照顺序排序。
-d   排序时，处理英文字母、数字及空格字符外，忽略其他的字符。
-f   排序时，将小写字母视为大写字母。
-i   排序时，除了040至176之间的ASCII字符外，忽略其他的字符。
-m   将几个排序好的文件进行合并。
-M   将前面3个字母依照月份的缩写进行排序。
-n   依照数值的大小排序。
-o<输出文件>   将排序后的结果存入指定的文件。
-r   以相反的顺序来排序。
-t<分隔字符>   指定排序时所用的栏位分隔字符。
-k   以第几列排序，配合-t分隔字符后用
+<起始栏位>-<结束栏位>   以指定的栏位来排序，范围由起始栏位到结束栏位的前一栏位。
```


> sort 文件名
> sort -u 文件名

注意区分 带不带-n的区别
> sort -n 文件名

> sort -nr 文件名1 -o 文件名2  // 将文件1中的数据排序后，输入到文件2中

sort的-t选项和-k选项
```
原文件
cat date 
2017-12-02
2017-01-09
2017-10-23
2017-04-24
```

这个文件有三列，列与列之间用“-”隔开了，第一列表示年，第二列表示月，第三列表示日。  
那么我想以月来排序，也就是以第二列来排序，如何利用sort实现？  
幸好，sort提供了-t选项，后面可以设定间隔符。指定了间隔符之后，就可以用-k来指定列数了。
```
sort -n -k 2 -t'-' date      // -t<分隔字符>   指定排序时所用的栏位分隔字符。  -k 选择以哪个区间进行排序
2017-01-09
2017-04-24
2017-10-23
2017-12-02
```



uniq
---------------
统计结果去除重复的行

注意：该命令首先比较相邻的行，然后除去第二行和该行的后续副本。重复的行一定相邻。所以使用它之前先排一次序。
uniq [ -c | -d | -u ] [ -f Fields ] [ -s Characters ] [ -Fields ] [ +Characters ] [ InFile [ OutFile ] ]
```
-c 在输出行前面加上每行在输入文件中出现的次数。  
-d 仅显示重复行。  
-u 仅显示不重复的行，根mysql的distinct功能上有点像（重复的行只显示一次）  
```
注意：  
1，对文本操作时，它一般会和sort命令进行组合使用，因为uniq相邻的重复行。需先对输入排序再uniq，如使用sort -u|uniq -u 。

2，对文本操作时，若域中为先空字符(通常包括空格以及制表符)，然后非空字符，域中字符前的空字符将被跳过




comm 两个文件之间的比较
===============
comm命令可以用于两个文件之间的比较，它有一些选项可以用来调整输出，以便执行交集、求差、以及差集操作。

+ 交集：打印出两个文件所共有的行。
+ 求差：打印出指定文件所包含的且不相同的行。
+ 差集：打印出包含在一个文件中，但不包含在其他指定文件中的行。

```
语法 
comm (选项) (参数)

选项
-1：不显示在第一个文件出现的内容；
-2：不显示在第二个文件中出现的内容；
-3：不显示同时在两个文件中都出现的内容。

参数
文件1：指定要比较的第一个有序文件；
文件2：指定要比较的第二个有序文件。
```

实例
```
[root@localhost text]# cat aaa.txt 
aaa
bbb
ccc
ddd
eee
111
222


[root@localhost text]# cat bbb.txt 
bbb
ccc
aaa
hhh
ttt
jjj


[root@localhost text]# comm aaa.txt bbb.txt 
aaa
                bbb
                ccc
        aaa
ddd
eee
111
222
        hhh
        ttt
        jjj

第一列  第二列  第三列

输出的第一列只包含在aaa.txt中出现的行，
第二列包含在bbb.txt中出现的行，
第三列包含在aaa.txt和bbb.txt中相同的行。
各列是以制表符（\t）作为定界符。


交集
------------
打印两个文件的交集，需要删除第一列和第二列：

[root@localhost text]# comm aaa.txt bbb.txt -1 -2
bbb
ccc


求差
------------
打印出两个文件中不相同的行，需要删除第三列：

[root@localhost text]# comm aaa.txt bbb.txt -3 | sed 's/^\t//'
aaa
aaa
ddd
eee
111
222
hhh
ttt
jjj

sed 's/^\t//' 是将制表符（\t）删除，以便把两列合并成一列。


差集
------------
通过删除不需要的列，可以得到aaa.txt和bbb.txt的差集：

aaa.txt的差集

[root@localhost text]# comm aaa.txt bbb.txt -2 -3
aaa
ddd
eee
111
222


bbb.txt的差集

[root@localhost text]# comm aaa.txt bbb.txt -1 -3
aaa
hhh
ttt
jjj
```


linux按行合并两个文件
---------------
paste 命令 
```
如下：
[root@205_152 ~]# cat 1.txt 
1
2
3
4
5

[root@205_152 ~]# cat 2.txt 
q
w
e
r
t
y

[root@205_152 ~]# paste 1.txt 2.txt 
1   q
2   w
3   e
4   r
5   t
    y

可以使用 -d 参数 加分割符
[root@205_152 ~]# paste -d: 1.txt 2.txt 
1:q
2:w
3:e
4:r
5:t
:y
```



kill 杀死多个进程
---------------
kill 进程号
kill -9 进程号

杀死多个进程依次排在后边就行了
kill -9 25718 25719 25811 25812 

如果按进程名杀死多个进程
```
ps aux|grep nginx|grep -v grep|awk '{print $2}'|xargs kill -9
如果进程中有斜杠的话可以转义
ps aux|grep task\/crond|grep -v grep|awk '{print $2}'|xargs kill -9
```

另外
killall nginx





nohup用法，注：nohup和&配合一起来用
---------------
nohup命令：如果你正在运行一个进程，而且你觉得在退出帐户时该进程还不会结束，那么可以使用nohup命令。该命令可以在你退出帐户/关闭终端之后继续运行相应的进程。nohup就是不挂起的意思( n ohang up)。

该命令的一般形式为：nohup command &

如果使用nohup命令提交作业，那么在缺省情况下该作业的所有输出都被重定向到一个名为nohup.out的文件中，除非另外指定了输出文件：
nohup command > myout.file 2>&1 &


用途：不挂断地运行命令。  
语法：nohup Command [ Arg … ] [　& ]  
描述：nohup 命令运行由 Command 参数和任何相关的 Arg 参数指定的命令，忽略所有挂断（SIGHUP）信号。在注销后使用 nohup 命令运行后台中的程序。要运行后台中的 nohup 命令，添加 & （ 表示”and”的符号）到命令的尾部。  

例：
```
nohup /root/start.sh &
在shell中回车后提示：
[~]$ appending output to nohup.out
原程序的的标准输出被自动改向到当前目录下的nohup.out文件，起到了log的作用。
```

仅使用&后台运行程序：xx.sh &
+ 结果会输出到终端
+ 使用Ctrl + C发送SIGINT信号，程序免疫
+ 关闭session发送SIGHUP信号，程序关闭

仅使用nohup运行程序： nohup xx.sh
+ 结果默认会输出到nohup.out
+ 使用Ctrl + C发送SIGINT信号，程序关闭
+ 关闭session发送SIGHUP信号，程序免疫

同时用nobup与&：nohup xx.sh &
+ 同时免疫SIGINT和SIGHUP信号

结论：平日线上经常使用nohup和&配合来启动程序。  





切割大文件
--------------
比如该文件file.log有10万行数据，现在想分4个进程处理。需要分割2.5万行一个文件。命令split可以做到。
split的用法比较简单，可以man split查看下手册。 
> split -l 25000 -d file.log prefix_name
```
-l 是按照行分割，
-d 是分割后的文件名按照数字，
-a 是分割后的文件个数位数（默认是2，做多就是99个；比如超过100个，-a可以写3）。
```




定向输出日志 >log >>log
---------------
```
0 表示标准输入，STDIN_FILENO
1 表示标准输出，STDOUT_FILENO
2 表示标准错误输出，STDERR_FILENO
> 默认为标准输出重定向，与 1> 相同
2>&1 意思是把 标准错误输出 重定向到 标准输出.
&>file 意思是把 标准输出 和 标准错误输出 都重定向到文件file中
```

例：
```
将test.c重定向为cat命令的输入源
cat < test.c 

将ls的结果从标准输出重定向为1.txt文本
ls > 1.txt 


符号 > 和 >> 的区别在于：
符号 > 用于覆盖，而>>用于追加。  
即:
ls > 1.txt 将ls的内容以覆盖的方式保存进1.txt，只保留最新的。
ls >> 1.txt 将ls的内容追加到1.txt中。


>>${LOG1} 2>&1     正确或错误结果追加到LOG文件里
>${LOG2} 2>&1       正确或错误结果覆写LOG文件

如：
/xxx/xxx/xxx.sh >>${LOG1} 2>&1
/xxx/xxx/xxx.sh >${LOG1} 2>&1
cd /xxxx/xxx && xxx.sh >${LOG1} 2>&1
```



vi中文乱码时
-------------
```
set encoding=utf8
```






















